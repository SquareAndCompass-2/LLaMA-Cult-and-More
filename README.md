
# Fun updates related to ChatGPT

# Apr, 2023

- 03: prompt engineering guide ([blog](https://www.promptingguide.ai/zh)), openai best practices ([blog](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api)), prompt prefect ([blog](https://promptperfect.jina.ai/)), prompt searching ([repo](https://github.com/MaHuanAAA/g_fair_prompting)), PromptInject ([repo](https://github.com/agencyenterprise/PromptInject)), auto prompt engineering ([blog](https://www.promptingguide.ai/zh/techniques/ape))
- 02: LMFlow ([blog](https://www.jiqizhixin.com/articles/2023-04-02), [repo](https://github.com/OptimalScale/LMFlow))
- 01: Vicuna-13B, fine-tuning LLaMA on 70K conversations from ShareGPT, more than 90% ChatGPT quality ([blog](https://vicuna.lmsys.org/), [repo](https://github.com/lm-sys/FastChat), [demo](https://chat.lmsys.org/), [data](https://github.com/lm-sys/FastChat/issues/90#issuecomment-1493250773))
- 01: Alpaca-CoT ([repo](https://github.com/PhoebusSi/Alpaca-CoT))
- 01: Official Apple Core ML Stable Diffusion Lib on M-series chips, ([repo](https://github.com/apple/ml-stable-diffusion), [MochiDiffusion](https://github.com/godly-devotion/MochiDiffusion), [swift-coreml-diffusers](https://github.com/huggingface/swift-coreml-diffusers))
- 01: PolyglotSiri Apple Shortcut, ([tweet](https://twitter.com/Munntein/status/1641683629968592897), [repo](https://github.com/Munntein/PolyglotSiri-Apple-Shortcut))
- 01: Twitter's Recommendation Algorithm ([repo](https://github.com/twitter/the-algorithm))

# Mar, 2023

- 31: Alpaca-LoRA-Serve gradio app ([tweet](https://twitter.com/algo_diver/status/1638525828773576704), [repo](https://github.com/deep-diver/Alpaca-LoRA-Serve))
- 31: GPT4 UI generation ([tweet](https://twitter.com/gdb/status/1641496253572997123))
- 31: ChatGPT outperform crowd-workers for text annotation tasks ([tweet](https://twitter.com/AlphaSignalAI/status/1641496876527517696))
- 31: BloombergGPT, 50B LLM outperform existing models on financial tasks ([tweet](https://twitter.com/omarsar0/status/1641787456436547584))
- 31: HuggingGPT, as an interface for LLMs to connect AI Models for solving comlicated AI tasks ([tweet](https://twitter.com/johnjnay/status/1641609645713129473))
- 31: Llama-X ([repo](https://github.com/AetherCortex/Llama-X))
- 30: ChatExplore ([tweet](https://twitter.com/omarsar0/status/1641444447304011776))
- 30: ColossalChat, ([medium](https://medium.com/@yangyou_berkeley/colossalchat-an-open-source-solution-for-cloning-chatgpt-with-a-complete-rlhf-pipeline-5edf08fb538b), [tweet](https://twitter.com/omarsar0/status/1641070883497205761), [repo](https://github.com/hpcaitech/ColossalAI/blob/main/applications/Chat/inference/server.py))
- 30: Chinese-LLaMA-Alpaca, ([repo](https://github.com/ymcui/Chinese-LLaMA-Alpaca))
- 30: ChatGLM-6B, An Open Bilingual Dialogue Language Model ([repo](https://github.com/THUDM/ChatGLM-6B))
- 29: Uncle Rabbit, the first conversational holographic AI ([tweet](https://twitter.com/ArturoJReal/status/1641129170100011035), [blog](https://feld.com/archives/2023/03/do-ai-rabbits-dream-of-holographic-carrots/))
- 29: chatgpt instead of siri ([tweet](https://twitter.com/punk2898/status/1641063874186346496))
- 29: LLaMA-Adapter, fine-tuning LLaMA with 1.2M learnable parameters in 1 hour ([repo](https://github.com/ZrrSkywalker/LLaMA-Adapter))
- 28: gpt4all, with ~800k GPT-3.5-Turbo Generations based on LLaMa ([repo](https://github.com/nomic-ai/gpt4all))
- 27: LLaMA voice chat + Siri TTS ([tweet](https://twitter.com/ggerganov/status/1640416314773700608))
- 26: LLaMA voice chat ([tweet](https://twitter.com/ggerganov/status/1640022482307502085))
- 22: Alpaca LoRA as a chatbot ([tweet](https://twitter.com/algo_diver/status/1638525828773576704), [repo](https://github.com/deep-diver/Alpaca-LoRA-Serve))
- 22: BELLE, ~1M chinese dataset, BLOOM-7B and LLaMA-7B fine-tuning ([repo](https://github.com/LianjiaTech/BELLE))
- 17: nlpcloud/instruct-gpt-j, gpt-j-6b on stanford alpaca dataset ([repo](https://nlpcloud.com/instruct-version-of-gpt-j-using-stanford-alpaca-dataset.html), [model](https://huggingface.co/nlpcloud/instruct-gpt-j-fp16))
- 13: Stanford Alpaca, A Strong Replicable Instruction-Following Model, a 52K dataset, LLaMA 7B ([blog](https://crfm.stanford.edu/2023/03/13/alpaca.html), [repo](https://github.com/tatsu-lab/stanford_alpaca))
- 05: llama-dl, high speed download of LLaMA model ([repo(deprecated)](https://github.com/shawwn/llama-dl), [model](https://huggingface.co/decapoda-research/llama-7b-hf))


## Feb, 2023

- 28: llama.cpp ([repo](https://github.com/ggerganov/llama.cpp))
- 28: ggml, 16-bit float and 4-bit quantization ([repo](https://github.com/ggerganov/ggml))
- 28: whisper.cpp ([repo](https://github.com/ggerganov/whisper.cpp))


## Jan, 2023

- llama_index: connect LLM with external data ([repo](https://github.com/jerryjliu/llama_index))
- text-generation-webui: A gradio web UI for deploy LLMs like GPT-J, LLaMA ([repo](https://github.com/oobabooga/text-generation-webui))
- A1111-Web-UI-Installer: A gradio web UI for deploy stable diffusion models ([repo](https://github.com/EmpireMediaScience/A1111-Web-UI-Installer))
- tldream/lama-cleaner: tiny little diffusion drawing app ([repo1](https://github.com/Sanster/tldream), [repo2](https://github.com/Sanster/lama-cleaner))

